from __future__ import annotations
from typing import TYPE_CHECKING, cast, overload

if TYPE_CHECKING:
    from kokoro import KPipeline, KModel
    from misaki.en import G2P, MToken
    from typing import (
        Any,
        Callable,
        Iterable,
        Optional,
        Tuple,
        List,
        Dict,
        Union,
        Sequence,
    )

    from audiobooks.project.spec import ChapterRecord

import warnings
from pathlib import Path

import soundfile as sf
import ffmpeg

import datetime


# %%


def master_audio_from_chapters(input_paths: list[Path], output_path: Path, **kwargs):
    input_streams = [ffmpeg.input(str(p)) for p in input_paths[:2]]

    output_args = {
        "c:a": "aac",
        "aac_coder": "fast",
        "b:a": "48k",
        "ac": 1,
        "ar": 24000,
    }
    output_args |= kwargs

    graph = (
        ffmpeg.concat(*input_streams, v=0, a=1)
        .filter("loudnorm", I=-16, TP=-1.5, LRA=11)
        .output(str(output_path), **output_args)
        .overwrite_output()
    )

    graph.run()


def m4b_from_master_audio(
    audio_path: Path,
    cover_path: Path,
    meta_path: Path,
    output_path: Path,
    **kwargs,
):

    audio_in = ffmpeg.input(str(audio_path))
    cover_in = ffmpeg.input(str(cover_path))
    meta_in = ffmpeg.input(str(meta_path), format="ffmetadata")

    a = audio_in.audio
    v = cover_in.video

    out = (
        ffmpeg.output(
            a,
            v,
            str(output_path),
            **{
                "c:a": "copy",
                "c:v": "copy",
                "map_metadata": 2,
                "map_chapters": 2,
                "disposition:v:0": "attached_pic",
                "movflags": "+faststart",
            },
        )
        # force meta_in to be part of the compiled graph by adding it as a global input
        # ffmpeg-python doesn’t have a perfect “unused input” concept; the most reliable way is to
        # compile explicitly or use overwrite_output and global args patterns.
        .global_args("-i", str(meta_path), "-f", "ffmetadata")
        .global_args("-metadata:s:v:0", "title=Cover")
        .global_args("-metadata:s:v:0", "comment=Cover (front)")
        .overwrite_output()
    )

    out.run()


ffmetadata_header = """\
;FFMETADATA1
title={book_title}
artist={artist}
genre=Audiobook
date={date}
comment=Generated by vinitlee on {today}
"""
ffmetadata_chapter = """
[CHAPTER]
TIMEBASE=1/{timebase_denom}
START={start}
END={end}
title={chapter_title}
"""


def generate_ffmetadata(
    dest: Path,
    title: str,
    artist: str,
    date: str,
    chapter_record: ChapterRecord,
):
    timebase_denom = 1000

    file_str = ffmetadata_header.format(
        book_title=title,
        artist=artist,
        date=date,
        today=datetime.datetime.now().strftime("%m/%d/%Y"),
    )

    start = 0
    end = 0
    for ch in chapter_record:
        end = start + int(ch.duration * timebase_denom)
        file_str += ffmetadata_chapter.format(
            timebase_denom=timebase_denom,
            start=start,
            end=end,
            chapter_title=ch.name,
        )
        start = end

    dest.write_text(file_str)
